---
---

@string{aps = {American Physical Society,}}

@book{einstein1920relativity,
  title={Relativity: the Special and General Theory},
  author={Einstein, Albert},
  year={1920},
  publisher={Methuen & Co Ltd},
  html={relativity.html}
}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein*†, A. and Podolsky*, B. and Rosen*, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  annotation={* Example use of superscripts<br>† Albert Einstein},
  selected={true},
  inspirehep_id = {3255}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@Article{einstein1905photoelectriceffect,
  bibtex_show={true},
  abbr={Ann. Phys.},
  title="{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}",
  author={Albert Einstein},
  abstract={This is the abstract text.},
  journal={Ann. Phys.},
  volume={322},
  number={6},
  pages={132--148},
  year={1905},
  doi={10.1002/andp.19053220607},
  award={Albert Einstein receveid the **Nobel Prize in Physics** 1921 *for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect*},
  award_name={Nobel Prize}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schrödinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif},
  abbr={Vision}
}

@inproceedings{DBLP:conf/wosp/HegemanJIT21,
  bibtex_show = {true},
  selected    = {false},
  preview     = {grademl.webp},
  pdf         = {2023-hotcloudperf-grademl.pdf},
  code        = {https://github.com/atlarge-research/grademl},
  abstract    = {Today, machine learning (ML) workloads are nearly ubiquitous. Over the past decade, much effort has been put into making ML model-training fast and efficient, e.g., by proposing new ML frameworks (such as TensorFlow, PyTorch), leveraging hardware support (TPUs, GPUs, FPGAs), and implementing new execution models (pipelines, distributed training). Matching this trend, considerable effort has also been put into performance analysis tools focusing on ML model-training. However, as we identify in this work, ML model training rarely happens in isolation and is instead one step in a larger ML workflow. Therefore, it is surprising that there exists no performance analysis tool that covers the entire life-cycle of ML workflows. Addressing this large conceptual gap, we envision in this work a holistic performance analysis tool for ML workflows. We analyze the state-of-practice and the state-of-the-art, presenting quantitative evidence about the performance of existing performance tools. We formulate our vision for holistic performance analysis of ML workflows along four design pillars: a unified execution model, lightweight collection of performance data, efficient data aggregation and presentation, and close integration in ML systems. Finally, we propose first steps towards implementing our vision as GradeML, a holistic performance analysis tool for ML workflows. Our preliminary work and experiments are open source at https://github.com/atlarge-research/grademl.},
  author      = {Tim Hegeman and
                 Matthijs Jansen and
                 Alexandru Iosup and
                 Animesh Trivedi},
  editor      = {Johann Bourcier and
                 Zhen Ming (Jack) Jiang and
                 Cor{-}Paul Bezemer and
                 Vittorio Cortellessa and
                 Daniele Di Pompeo and
                 Ana Lucia Varbanescu},
  title       = {GradeML: Towards Holistic Performance Analysis for Machine Learning
                 Workflows},
  booktitle   = {{ICPE} '21: {ACM/SPEC} International Conference on Performance Engineering,
                 Virtual Event, France, April 19-21, 2021, Companion Volume},
  pages       = {57--63},
  publisher   = {{ACM}},
  year        = {2021},
  url         = {https://doi.org/10.1145/3447545.3451185},
  doi         = {10.1145/3447545.3451185},
  timestamp   = {Sun, 02 Oct 2022 16:17:46 +0200},
  biburl      = {https://dblp.org/rec/conf/wosp/HegemanJIT21.bib},
  bibsource   = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/wosp/JansenDTI23,
  bibtex_show = {true},
  selected    = {false},
  preview     = {metaverse-wifi.webp},
  pdf         = {2023-hotcloudperf-metaverse.pdf},
  code        = {https://github.com/atlarge-research/measuring-the-metaverse},
  slides      = {2023-hotcloudperf-metaverse-pres.pdf},
  abstract    = {Extending human societies into virtual space through the construction of a metaverse has been a long-term challenge in both industry and academia. Achieving this challenge is now closer than ever due to advances in computer systems, facilitating large-scale online platforms such as Minecraft and Roblox that fulfill an increasing number of societal needs, and extended reality (XR) hardware, which provides users with state-of-the-art immersive experiences. For a metaverse to succeed, we argue that all involved systems must provide consistently good performance. However, there is a lack of knowledge on the performance characteristics of extended reality devices. In this paper, we address this gap and focus on extended- and virtual-reality hardware. We synthesize a user-centered system model that models common deployments of XR hardware and their trade-offs. Based on this model, we design and conduct real-world experiments with Meta's flagship virtual reality device, the Quest Pro. We highlight two surprising results from our findings which show that (i) under our workload, the battery drains 15% faster when using wireless offloading compared to local execution, and (ii) the outdated 2.4 GHz WiFi4 gives surprisingly good performance, with 99% of samples achieving a frame rate of at least 65 Hz, compared to the 72 Hz performance target. Our experimental setup and data are available at https://github.com/atlarge-research/measuring-the-metaverse.},
  author      = {Matthijs Jansen and
                 Jesse Donkervliet and
                 Animesh Trivedi and
                 Alexandru Iosup},
  editor      = {Marco Vieira and
                 Valeria Cardellini and
                 Antinisca Di Marco and
                 Petr Tuma},
  title       = {Can My WiFi Handle the Metaverse? {A} Performance Evaluation Of Meta's
                 Flagship Virtual Reality Hardware},
  booktitle   = {Companion of the 2023 {ACM/SPEC} International Conference on Performance
                 Engineering, {ICPE} 2023, Coimbra, Portugal, April 15-19, 2023},
  pages       = {297--303},
  publisher   = {{ACM}},
  year        = {2023},
  url         = {https://doi.org/10.1145/3578245.3585022},
  doi         = {10.1145/3578245.3585022},
  timestamp   = {Sat, 29 Apr 2023 19:25:35 +0200},
  biburl      = {https://dblp.org/rec/conf/wosp/JansenDTI23.bib},
  bibsource   = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/wosp/JansenWTI23,
  bibtex_show = {true},
  selected    = {true},
  preview     = {continuum-framework.webp},
  pdf         = {2023-fastcontinuum-continuum.pdf},
  code        = {https://github.com/atlarge-research/continuum},
  slides      = {2023-fastcontinuum-continuum-pres.pdf},
  abstract    = {As the next generation of diverse workloads like autonomous driving and augmented/virtual reality evolves, computation is shifting from cloud-based services to the edge, leading to the emergence of a cloud-edge compute continuum. This continuum promises a wide spectrum of deployment opportunities for workloads that can leverage the strengths of cloud (scalable infrastructure, high reliability), edge (energy efficient, low latencies), and endpoints (sensing, user-owned). Designing and deploying software in the continuum is complex because of the variety of available hardware, each with unique properties and trade-offs. In practice, developers have limited access to these resources, limiting their ability to create software deployments. To simplify research and development in the compute continuum, in this paper, we propose Continuum, a framework for automated infrastructure deployment and benchmarking that helps researchers and engineers to deploy and test their use cases in a few lines of code. Continuum can automatically deploy a wide variety of emulated infrastructures and networks locally and in the cloud, install software for operating services and resource managers, and deploy and benchmark applications for users with diverse configuration options. In our evaluation, we show how our design covers these requirements, allowing Continuum to be (i) highly flexible, supporting any computing model, (ii) highly configurable, allowing users to alter framework components using an intuitive API, and (iii) highly extendable, allowing users to add support for more infrastructure, applications, and more. Continuum is available at https://github.com/atlarge-research/continuum.},
  author      = {Matthijs Jansen and
                 Linus Wagner and
                 Animesh Trivedi and
                 Alexandru Iosup},
  editor      = {Marco Vieira and
                 Valeria Cardellini and
                 Antinisca Di Marco and
                 Petr Tuma},
  title       = {Continuum: Automate Infrastructure Deployment and Benchmarking in
                 the Compute Continuum},
  booktitle   = {Companion of the 2023 {ACM/SPEC} International Conference on Performance
                 Engineering, {ICPE} 2023, Coimbra, Portugal, April 15-19, 2023},
  pages       = {181--188},
  publisher   = {{ACM}},
  year        = {2023},
  url         = {https://doi.org/10.1145/3578245.3584936},
  doi         = {10.1145/3578245.3584936},
  timestamp   = {Sat, 29 Apr 2023 19:25:34 +0200},
  biburl      = {https://dblp.org/rec/conf/wosp/JansenWTI23.bib},
  bibsource   = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/ccgrid/JansenAPTI23,
  bibtex_show = {true},
  selected    = {true},
  preview     = {2023-ccgrid-refarch.webp},
  pdf         = {2023-ccgrid-refarch.pdf},
  code        = {https://github.com/atlarge-research/continuum},
  slides      = {2023-ccgrid-refarch-pres.pdf},
  abstract    = {As the next generation of diverse workloads like autonomous driving and augmented/virtual reality evolves, computation is shifting from cloud-based services to the edge, leading to the emergence of a cloud-edge compute continuum. This continuum promises a wide spectrum of deployment opportunities for workloads that can leverage the strengths of cloud (scalable infrastructure, high reliability) and edge (energy efficient, low latencies). Despite its promises, the continuum has only been studied in silos of various computing models, thus lacking strong end-to-end theoretical and engineering foundations for computing and resource management across the continuum. Consequently, devel-opers resort to ad hoc approaches to reason about performance and resource utilization of workloads in the continuum. In this work, we conduct a first-of-its-kind systematic study of various computing models, identify salient properties, and make a case to unify them under a compute continuum reference architecture. This architecture provides an end-to-end analysis framework for developers to reason about resource management, workload distribution, and performance analysis. We demonstrate the utility of the reference architecture by analyzing two popular continuum workloads, deep learning and industrial IoT. We have developed an accompanying deployment and benchmarking framework and first-order analytical model for quantitative reasoning of continuum workloads. The framework is open-sourced and available at https://github.com/atlarge-research/continuum.},
  author      = {Matthijs Jansen and
                 Auday Al{-}Dulaimy and
                 Alessandro V. Papadopoulos and
                 Animesh Trivedi and
                 Alexandru Iosup},
  editor      = {Yogesh Simmhan and
                 Ilkay Altintas and
                 Ana Lucia Varbanescu and
                 Pavan Balaji and
                 Abhinandan S. Prasad and
                 Lorenzo Carnevale},
  title       = {The {SPEC-RG} Reference Architecture for The Compute Continuum},
  booktitle   = {23rd {IEEE/ACM} International Symposium on Cluster, Cloud and Internet
                 Computing, CCGrid 2023, Bangalore, India, May 1-4, 2023},
  pages       = {469--484},
  publisher   = {{IEEE}},
  year        = {2023},
  url         = {https://doi.org/10.1109/CCGrid57682.2023.00051},
  doi         = {10.1109/CCGrid57682.2023.00051},
  timestamp   = {Fri, 21 Jul 2023 22:25:52 +0200},
  biburl      = {https://dblp.org/rec/conf/ccgrid/JansenAPTI23.bib},
  bibsource   = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/wosp/HegemanJIT21,
  bibtex_show = {true},
  selected    = {false},
  preview     = {grademl.webp},
  pdf         = {2023-hotcloudperf-grademl.pdf},
  code        = {https://github.com/atlarge-research/grademl},
  abstract    = {Today, machine learning (ML) workloads are nearly ubiquitous. Over the past decade, much effort has been put into making ML model-training fast and efficient, e.g., by proposing new ML frameworks (such as TensorFlow, PyTorch), leveraging hardware support (TPUs, GPUs, FPGAs), and implementing new execution models (pipelines, distributed training). Matching this trend, considerable effort has also been put into performance analysis tools focusing on ML model-training. However, as we identify in this work, ML model training rarely happens in isolation and is instead one step in a larger ML workflow. Therefore, it is surprising that there exists no performance analysis tool that covers the entire life-cycle of ML workflows. Addressing this large conceptual gap, we envision in this work a holistic performance analysis tool for ML workflows. We analyze the state-of-practice and the state-of-the-art, presenting quantitative evidence about the performance of existing performance tools. We formulate our vision for holistic performance analysis of ML workflows along four design pillars: a unified execution model, lightweight collection of performance data, efficient data aggregation and presentation, and close integration in ML systems. Finally, we propose first steps towards implementing our vision as GradeML, a holistic performance analysis tool for ML workflows. Our preliminary work and experiments are open source at https://github.com/atlarge-research/grademl.},
  author      = {Tim Hegeman and
                 Matthijs Jansen and
                 Alexandru Iosup and
                 Animesh Trivedi},
  editor      = {Johann Bourcier and
                 Zhen Ming (Jack) Jiang and
                 Cor{-}Paul Bezemer and
                 Vittorio Cortellessa and
                 Daniele Di Pompeo and
                 Ana Lucia Varbanescu},
  title       = {GradeML: Towards Holistic Performance Analysis for Machine Learning
                 Workflows},
  booktitle   = {{ICPE} '21: {ACM/SPEC} International Conference on Performance Engineering,
                 Virtual Event, France, April 19-21, 2021, Companion Volume},
  pages       = {57--63},
  publisher   = {{ACM}},
  year        = {2021},
  url         = {https://doi.org/10.1145/3447545.3451185},
  doi         = {10.1145/3447545.3451185},
  timestamp   = {Sun, 02 Oct 2022 16:17:46 +0200},
  biburl      = {https://dblp.org/rec/conf/wosp/HegemanJIT21.bib},
  bibsource   = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/wosp/JansenDTI23,
  bibtex_show = {true},
  selected    = {false},
  preview     = {metaverse-wifi.webp},
  pdf         = {2023-hotcloudperf-metaverse.pdf},
  code        = {https://github.com/atlarge-research/measuring-the-metaverse},
  slides      = {2023-hotcloudperf-metaverse-pres.pdf},
  abstract    = {Extending human societies into virtual space through the construction of a metaverse has been a long-term challenge in both industry and academia. Achieving this challenge is now closer than ever due to advances in computer systems, facilitating large-scale online platforms such as Minecraft and Roblox that fulfill an increasing number of societal needs, and extended reality (XR) hardware, which provides users with state-of-the-art immersive experiences. For a metaverse to succeed, we argue that all involved systems must provide consistently good performance. However, there is a lack of knowledge on the performance characteristics of extended reality devices. In this paper, we address this gap and focus on extended- and virtual-reality hardware. We synthesize a user-centered system model that models common deployments of XR hardware and their trade-offs. Based on this model, we design and conduct real-world experiments with Meta's flagship virtual reality device, the Quest Pro. We highlight two surprising results from our findings which show that (i) under our workload, the battery drains 15% faster when using wireless offloading compared to local execution, and (ii) the outdated 2.4 GHz WiFi4 gives surprisingly good performance, with 99% of samples achieving a frame rate of at least 65 Hz, compared to the 72 Hz performance target. Our experimental setup and data are available at https://github.com/atlarge-research/measuring-the-metaverse.},
  author      = {Matthijs Jansen and
                 Jesse Donkervliet and
                 Animesh Trivedi and
                 Alexandru Iosup},
  editor      = {Marco Vieira and
                 Valeria Cardellini and
                 Antinisca Di Marco and
                 Petr Tuma},
  title       = {Can My WiFi Handle the Metaverse? {A} Performance Evaluation Of Meta's
                 Flagship Virtual Reality Hardware},
  booktitle   = {Companion of the 2023 {ACM/SPEC} International Conference on Performance
                 Engineering, {ICPE} 2023, Coimbra, Portugal, April 15-19, 2023},
  pages       = {297--303},
  publisher   = {{ACM}},
  year        = {2023},
  url         = {https://doi.org/10.1145/3578245.3585022},
  doi         = {10.1145/3578245.3585022},
  timestamp   = {Sat, 29 Apr 2023 19:25:35 +0200},
  biburl      = {https://dblp.org/rec/conf/wosp/JansenDTI23.bib},
  bibsource   = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/wosp/JansenWTI23,
  bibtex_show = {true},
  selected    = {true},
  preview     = {continuum-framework.webp},
  pdf         = {2023-fastcontinuum-continuum.pdf},
  code        = {https://github.com/atlarge-research/continuum},
  slides      = {2023-fastcontinuum-continuum-pres.pdf},
  abstract    = {As the next generation of diverse workloads like autonomous driving and augmented/virtual reality evolves, computation is shifting from cloud-based services to the edge, leading to the emergence of a cloud-edge compute continuum. This continuum promises a wide spectrum of deployment opportunities for workloads that can leverage the strengths of cloud (scalable infrastructure, high reliability), edge (energy efficient, low latencies), and endpoints (sensing, user-owned). Designing and deploying software in the continuum is complex because of the variety of available hardware, each with unique properties and trade-offs. In practice, developers have limited access to these resources, limiting their ability to create software deployments. To simplify research and development in the compute continuum, in this paper, we propose Continuum, a framework for automated infrastructure deployment and benchmarking that helps researchers and engineers to deploy and test their use cases in a few lines of code. Continuum can automatically deploy a wide variety of emulated infrastructures and networks locally and in the cloud, install software for operating services and resource managers, and deploy and benchmark applications for users with diverse configuration options. In our evaluation, we show how our design covers these requirements, allowing Continuum to be (i) highly flexible, supporting any computing model, (ii) highly configurable, allowing users to alter framework components using an intuitive API, and (iii) highly extendable, allowing users to add support for more infrastructure, applications, and more. Continuum is available at https://github.com/atlarge-research/continuum.},
  author      = {Matthijs Jansen and
                 Linus Wagner and
                 Animesh Trivedi and
                 Alexandru Iosup},
  editor      = {Marco Vieira and
                 Valeria Cardellini and
                 Antinisca Di Marco and
                 Petr Tuma},
  title       = {Continuum: Automate Infrastructure Deployment and Benchmarking in
                 the Compute Continuum},
  booktitle   = {Companion of the 2023 {ACM/SPEC} International Conference on Performance
                 Engineering, {ICPE} 2023, Coimbra, Portugal, April 15-19, 2023},
  pages       = {181--188},
  publisher   = {{ACM}},
  year        = {2023},
  url         = {https://doi.org/10.1145/3578245.3584936},
  doi         = {10.1145/3578245.3584936},
  timestamp   = {Sat, 29 Apr 2023 19:25:34 +0200},
  biburl      = {https://dblp.org/rec/conf/wosp/JansenWTI23.bib},
  bibsource   = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/ccgrid/JansenAPTI23,
  bibtex_show = {true},
  selected    = {true},
  preview     = {2023-ccgrid-refarch.webp},
  pdf         = {2023-ccgrid-refarch.pdf},
  code        = {https://github.com/atlarge-research/continuum},
  slides      = {2023-ccgrid-refarch-pres.pdf},
  abstract    = {As the next generation of diverse workloads like autonomous driving and augmented/virtual reality evolves, computation is shifting from cloud-based services to the edge, leading to the emergence of a cloud-edge compute continuum. This continuum promises a wide spectrum of deployment opportunities for workloads that can leverage the strengths of cloud (scalable infrastructure, high reliability) and edge (energy efficient, low latencies). Despite its promises, the continuum has only been studied in silos of various computing models, thus lacking strong end-to-end theoretical and engineering foundations for computing and resource management across the continuum. Consequently, devel-opers resort to ad hoc approaches to reason about performance and resource utilization of workloads in the continuum. In this work, we conduct a first-of-its-kind systematic study of various computing models, identify salient properties, and make a case to unify them under a compute continuum reference architecture. This architecture provides an end-to-end analysis framework for developers to reason about resource management, workload distribution, and performance analysis. We demonstrate the utility of the reference architecture by analyzing two popular continuum workloads, deep learning and industrial IoT. We have developed an accompanying deployment and benchmarking framework and first-order analytical model for quantitative reasoning of continuum workloads. The framework is open-sourced and available at https://github.com/atlarge-research/continuum.},
  author      = {Matthijs Jansen and
                 Auday Al{-}Dulaimy and
                 Alessandro V. Papadopoulos and
                 Animesh Trivedi and
                 Alexandru Iosup},
  editor      = {Yogesh Simmhan and
                 Ilkay Altintas and
                 Ana Lucia Varbanescu and
                 Pavan Balaji and
                 Abhinandan S. Prasad and
                 Lorenzo Carnevale},
  title       = {The {SPEC-RG} Reference Architecture for The Compute Continuum},
  booktitle   = {23rd {IEEE/ACM} International Symposium on Cluster, Cloud and Internet
                 Computing, CCGrid 2023, Bangalore, India, May 1-4, 2023},
  pages       = {469--484},
  publisher   = {{IEEE}},
  year        = {2023},
  url         = {https://doi.org/10.1109/CCGrid57682.2023.00051},
  doi         = {10.1109/CCGrid57682.2023.00051},
  timestamp   = {Fri, 21 Jul 2023 22:25:52 +0200},
  biburl      = {https://dblp.org/rec/conf/ccgrid/JansenAPTI23.bib},
  bibsource   = {dblp computer science bibliography, https://dblp.org}
}

@article{10207712,
  bibtex_show = {true},
  selected    = {false},
  preview     = {2023-ieee-ic-nvn.webp},
  pdf         = {2023-ieee-ic-nvn.pdf},
  abstract    = {The article discusses the emerging non-von Neumann computer architectures and their integration in the computing continuum for supporting modern distributed applications, including artificial intelligence, big data, and scientific computing. It provides a detailed summary of the available and emerging non-von Neumann architectures, which range from power-efficient single-board accelerators to quantum and neuromorphic computers. Furthermore, it explores their potential benefits for revolutionizing data processing and analysis in various societal, science, and industry fields. The paper provides a detailed analysis of the most widely used class of distributed applications and discusses the difficulties in their execution over the computing continuum, including communication, interoperability, orchestration, and sustainability issues.},
  author      = {Kimovski, Dragi and Saurabh, Nishant and Jansen, Matthijs and Aral, Atakan and Al-Dulaimy, Auday and Bondi, André B. and Galletta, Antonino and Papadopoulos, Alessandro V. and Iosup, Alexandru and Prodan, Radu},
  journal     = {IEEE Internet Computing},
  title       = {Beyond von Neumann in the Computing Continuum: Architectures, Applications, and Future Directions},
  year        = {2023},
  volume      = {},
  number      = {},
  pages       = {1-11},
  doi         = {10.1109/MIC.2023.3301010}
}

@inproceedings{DBLP:conf/sc/JansenCV20,
  bibtex_show = {true},
  selected    = {false},
  preview     = {ddlbench.webp},
  pdf         = {2023-dls-ddlbench.pdf},
  code        = {https://github.com/sara-nl/DDLBench},
  slides      = {2023-dls-ddlbench-pres.pdf},
  abstract    = {Due to its many applications across various fields of research, engineering, and daily life, deep learning has seen a surge in popularity. Therefore, larger and more expressive models have been proposed, with examples like Turing-NLG using as many as 17 billion parameters. Training these very large models becomes increasingly difficult due to the high computational costs and large memory footprint. Therefore, several approaches for distributed training based on data parallelism (e.g., Horovod) and model/pipeline parallelism (e.g., GPipe, PipeDream) have emerged. In this work, we focus on an in-depth comparison of three different parallelism models that address these needs: data, model and pipeline parallelism. To this end, we provide an analytical comparison of the three, both in terms of computation time and memory usage, and introduce DDLBench, a comprehensive (open-source, ready-to-use) benchmark suite to quantify these differences in practice. Through in-depth performance analysis and experimentation with various models, datasets, distribution models and hardware systems, we demonstrate that DDLBench can accurately quantify the capability of a given system to perform distributed deep learning (DDL). By comparing our analytical models with the benchmarking results, we show how the performance of real-life implementations diverges from these analytical models, thus requiring benchmarking to capture the in-depth complexity of the frameworks themselves.},
  author      = {Jansen, Matthijs and Codreanu, Valeriu and Varbanescu, Ana Lucia},
  title       = {DDLBench: Towards a Scalable Benchmarking Infrastructure for Distributed Deep Learning},
  booktitle   = {Deep Learning on Supercomputers},
  pages       = {31--39},
  publisher   = {{IEEE}},
  year        = {2020},
  url         = {https://doi.org/10.1109/DLS51937.2020.00009},
  doi         = {10.1109/DLS51937.2020.00009},
  biburl      = {https://dblp.org/rec/conf/sc/JansenCV20.bib},
  bibsource   = {dblp computer science bibliography, https://dblp.org}
}

@article{ALDULAIMY2024101272,
  bibtex_show = {true},
  selected    = {false},
  preview     = {2024-sc-iot-compcont.webp},
  pdf         = {2024-sc-iot-compcont.pdf},
  abstract    = {In the era of the IoT revolution, applications are becoming ever more sophisticated and accompanied by diverse functional and non-functional requirements, including those related to computing resources and performance levels. Such requirements make the development and implementation of these applications complex and challenging. Computing models, such as cloud computing, can provide applications with on-demand computation and storage resources to meet their needs. Although cloud computing is a great enabler for IoT and endpoint devices, its limitations make it unsuitable to fulfill all design goals of novel applications and use cases. Instead of only relying on cloud computing, leveraging and integrating resources at different layers (like IoT, edge, and cloud) is necessary to form and utilize a computing continuum. The layers' integration in the computing continuum offers a wide range of innovative services, but it introduces new challenges (e.g., monitoring performance and ensuring security) that need to be investigated. A better grasp and more profound understanding of the computing continuum can guide researchers and developers in tackling and overcoming such challenges. Thus, this paper provides a comprehensive and unified view of the computing continuum. The paper discusses computing models in general with a focus on cloud computing, the computing models that emerged beyond the cloud, and the communication technologies that enable computing in the continuum. In addition, two novel reference architectures are presented in this work: one for edge-cloud computing models and the other for edge–cloud communication technologies. We demonstrate real use cases from different application domains (like industry and science) to validate the proposed reference architectures, and we show how these use cases map onto the reference architectures. Finally, the paper highlights key points that express the authors' vision about efficiently enabling and utilizing the computing continuum in the future.},
  author      = {Al-Dulaimy, Auday and Jansen, Matthijs and Johansson, Bjarne and Trivedi, Animesh and Iosup, Alexandru and Ashjaei, Mohammad and Galletta, Antonino and Kimovski, Dragi and Prodan, Radu and Tserpes, Konstantinos and Kousiouris, George and Giannakos, Chris and Brandic, Ivona and Ali, Nawfal and Bondi, André B. and Papadopoulos, Alessandro V.},
  journal     = {Internet of Things},
  title       = {The computing continuum: From IoT to the cloud},
  year        = {2024},
  volume      = {27},
  pages       = {101272},
  issn        = {2542-6605},
  doi         = {https://doi.org/10.1016/j.iot.2024.101272},
  url         = {https://www.sciencedirect.com/science/article/pii/S2542660524002130},
  keywords    = {Computing continuum, Cloud computing, Fog computing, Edge computing, Mobile cloud computing, Multi-access edge computing, SDN, NFV, IoT, Use case, Reference architecture}
}

@inproceedings{2024-ccgrid-stosys-edu,
  bibtex_show = {true},
  selected    = {false},
  preview     = {2024-ccgrid-stosys-edu.webp},
  pdf         = {2024-ccgrid-stosys-edu.pdf},
  code        = {https://atlarge-research.com/courses/storage-systems-vu/},
  slides      = {https://atlarge-research.com/courses/storage-systems-vu/},
  abstract    = {We live in a data-centric world where many fundamental shifts in our daily lives are powered by Big Data. To meet the performance, cost, and energy demands of modern Big Data systems, there have been significant technological and engineering breakthroughs in the field of storage systems with novel hardware innovations and software architectures. Nevertheless, a typical computer science student still associates data storage solely with the technology of hard disk drives (HDD), which was invented six decades ago. One key reason for this association is the lack of courses on modern storage systems in computer science education curricula. In this paper, we make a concerted effort to summarize the state of storage systems education across universities, popular textbooks, and policies (ACM/IEEE). We make a case that the storage systems should have its own home course in educational curricula. We report on our experience of designing and offering one such course at the Vrije Universiteit, Amsterdam over the past four years. We further contribute to the educational material in this direction by making the course lectures, video recordings, assignments, and grading framework freely and openly accessible at https://atlarge-research.com/courses/storage-systems-vu.},
  author      = {Trivedi, Animesh and Jansen, Matthijs and Doekemeijer, Krijn and Talluri, Sacheendra and Tehrany, Nick},
  booktitle   = {2024 IEEE 24th International Symposium on Cluster, Cloud and Internet Computing (CCGrid)},
  title       = {Reviving Storage Systems Education in the 21st Century — An experience report},
  year        = {2024},
  volume      = {},
  number      = {},
  pages       = {616-625},
  keywords    = {Technological innovation;Costs;Software architecture;Education;Memory;Big Data;Hard disks;Hardware;Computer science education;Video recording;Storage systems;Education;Experience report},
  doi         = {10.1109/CCGrid59990.2024.00074}
}
